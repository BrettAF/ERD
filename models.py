# -*- coding: utf-8 -*-
"""Models

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sbh0sgFnhcrcW02DCMiE4j-JAQ0ekBrt
"""

import tensorflow as tf
from tensorflow import keras
from keras import layers
from tensorflow.python import training
import numpy as np
import time
import csv

#This function is the same as the last, but with the seizures excluded
def labelVector2(labels):
  zero_vector=[1,0]
  one_vector =[0,1]
  new_array=[]
  for i in labels:
    if i==0:
        new_array.append(zero_vector)
    else :
        new_array.append(one_vector)
  new_array=np.array(new_array)
  return new_array

batch_size=200
number_of_epochs=21
window_size = 600
number_of_channels = 18

training_data=np.load("training_data.npy")
testing_data=np.load("testing_data.npy")
validation_data=np.load("validation_data.npy")

training_labels=np.load("training_lables.npy")
testing_labels=np.load("testing_lables.npy")
validation_labels=np.load("validation_lables.npy")

number_of_channels=training_data.shape[2]
window_size=training_data.shape[1]

training_labels=labelVector2(training_labels)
testing_labels=labelVector2(testing_labels)
validation_labels=labelVector2(validation_labels)

learning_rate=tf.keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate=.01,
                                                                first_decay_steps=20, t_mul=2.0, m_mul=1.0, alpha=0.0, name=None)
opt = keras.optimizers.legacy.Adam(learning_rate=learning_rate)

# normalized .5466,
input_shape = ( window_size, number_of_channels, 1)
training_data = training_data.reshape(-1,window_size, number_of_channels, 1)
validation_data = validation_data.reshape(-1,window_size, number_of_channels, 1)
testing_data = testing_data.reshape(-1,window_size, number_of_channels, 1)

print("training  ",training_data.shape,",",training_labels.shape)
m2Dlstm = keras.Sequential([
  layers.Conv2D(filters=32, kernel_size=(5,5) ,input_shape=input_shape),
  layers.Conv2D(filters=16, kernel_size=(3,3)),
  layers.MaxPool2D( pool_size=(11, 5)),
  layers.Reshape((54,32)),
  layers.LSTM(90, activation='relu' ),
  layers.Dense(75),
  layers.Dense(40),
  layers.Dense(2)
])
print('\n',m2Dlstm.summary())
m2Dlstm.compile(
              optimizer='Adam',
              loss=tf.keras.losses.CategoricalCrossentropy(),
              metrics=['accuracy'])

m2Dlstm.fit(training_data, training_labels, batch_size=batch_size, epochs=number_of_epochs, validation_data=(validation_data, validation_labels))
m2Dlstm.save("m2dlstm")

input_shape = ( window_size, number_of_channels, 1)


m1DLSTM = keras.Sequential([
  layers.Conv1D(filters=64, kernel_size=3, input_shape=input_shape),
  layers.Conv1D(filters=64, kernel_size=3),
  layers.MaxPool2D(),
  layers.Reshape([300,448]),
  layers.LSTM(100, activation='relu' ),
  layers.Dense(100),
  layers.Dense(50),
  layers.Dense(2)

])
print(m1DLSTM.summary())
m1DLSTM.compile(
              optimizer='Adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
m1DLSTM.fit(training_data, training_labels, batch_size=batch_size, epochs=number_of_epochs, validation_data=(validation_data, validation_labels))
m1DLSTM.save('m1DLSTM')

input_shape = ( window_size, number_of_channels, 1)
training_data = training_data.reshape(-1,window_size, number_of_channels, 1)

m2Dconv = keras.Sequential([
  layers.Conv2D(filters=32, kernel_size=(5,5) ,input_shape=input_shape),
  layers.Conv2D(filters=16, kernel_size=(3,3)),
  layers.MaxPool2D( pool_size=(50, 5)),
  layers.Flatten(),
  layers.Dense(100),
  layers.Dense(2)
])
print(m2Dconv.summary())
m2Dconv.compile(
              optimizer='Adam',
              loss=tf.keras.losses.CategoricalCrossentropy(),
              metrics=['accuracy'])

m2Dconv.fit(training_data, training_labels, batch_size=batch_size, epochs=number_of_epochs, validation_data=(validation_data, validation_labels))
m2Dconv.save("m2DLSTM")

curr_time = str(time.strftime("%H:%M", time.localtime()))

with open(''+curr_time+'.txt',"w") as writer:
  writer.write("batch size:",batch_size,"\tnumber of epochs:",number_of_epochs)
  print('\n--Accuracy on testing data--')

  print('m2Dlstm')
  test_loss, test_acc = m2Dlstm.evaluate(testing_data,testing_labels, verbose=2)
  print( test_acc)
  writer.writerow('m2Dlstm:\t test loss:',test_loss, ", test acc:",test_acc)

  print('m1DLSTM')
  test_loss, test_acc = m1DLSTM.evaluate(testing_data,testing_labels, verbose=2)
  print( test_acc)
  writer.writerow('m1DLSTM:\t test loss:',test_loss, ", test acc:",test_acc)

  print('m2Dconv')
  test_loss, test_acc = m2Dconv.evaluate(testing_data,testing_labels, verbose=2)
  print( test_acc)
  writer.writerow('m2Dconv:\t test loss:',test_loss, ", test acc:",test_acc)
  writer.close







